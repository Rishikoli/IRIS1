# Project IRIS - Enhanced System Design Document

## Overview

This document presents the enhanced system design for Project IRIS, incorporating the latest advancements in Agent 1 and Agent 2 with Yahoo Finance integration, 29 comprehensive forensic metrics, and real-time data processing capabilities.

## Enhanced Architecture Overview

### ğŸš€ Enhanced Agent Architecture

The enhanced IRIS system features two highly sophisticated agents operating simultaneously:

**Agent 1 (Enhanced Data Ingestion):**
- Multi-source data integration (FMP, NSE, BSE, Yahoo Finance)
- Real-time Yahoo Finance API integration
- Enhanced field mapping with 29 comprehensive metrics
- Pandas-based NaN detection and data validation
- Multi-quarter historical data processing

**Agent 2 (Enhanced Forensic Analysis):**
- 29 comprehensive forensic analysis metrics
- Real-time data processing capabilities
- Enhanced field mapping consistency
- Multi-quarter analysis support
- Production-ready pipeline integration

## Enhanced System Architecture

### Real-time Data Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Yahoo Finance â”‚â”€â”€â”€â–¶â”‚  Agent 1        â”‚â”€â”€â”€â–¶â”‚  Agent 2        â”‚
â”‚   (Real-time)   â”‚    â”‚  (Ingestion)    â”‚    â”‚  (Analysis)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   FMP API       â”‚â”€â”€â”€â–¶â”‚  - Field        â”‚â”€â”€â”€â–¶â”‚  - Vertical     â”‚
â”‚   (Historical)  â”‚    â”‚    Mapping      â”‚    â”‚    Analysis     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚  - Pandas       â”‚    â”‚  - Horizontal   â”‚
â”‚   NSE Portal    â”‚â”€â”€â”€â–¶â”‚    NaN          â”‚â”€â”€â”€â–¶â”‚    Analysis     â”‚
â”‚   (Indian)      â”‚    â”‚    Detection    â”‚    â”‚  - Financial    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚    Ratios       â”‚
â”‚   BSE Portal    â”‚â”€â”€â”€â–¶â”‚  - Multi-       â”‚â”€â”€â”€â–¶â”‚  - 29 Metrics   â”‚
â”‚   (Indian)      â”‚    â”‚    Quarter      â”‚    â”‚  - Real-time    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    Processing   â”‚    â”‚    Processing   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Enhanced Agent 1: Data Ingestion Agent

### Core Functionality

#### Multi-Source Data Integration
```python
class DataIngestionAgent:
    def __init__(self):
        self.yahoo_client = YahooFinanceClient()
        self.fmp_client = FMPAPIClient()
        self.nse_client = NSEClient()
        self.bse_client = BSEClient()

    async def get_financials(self, symbol: str, source: str, periods: int = 3):
        """Enhanced multi-source data fetching"""
        if source == "yahoo":
            return await self._get_yahoo_financials(symbol, periods)
        elif source == "fmp":
            return await self._get_fmp_financials(symbol, periods)
        # ... additional sources
```

#### Enhanced Yahoo Finance Integration
```python
async def _get_yahoo_financials(self, symbol: str, periods: int) -> Dict[str, Any]:
    """Fetch real-time data from Yahoo Finance"""
    ticker = yf.Ticker(symbol)

    # Real-time market data
    info = ticker.info

    # Quarterly financial statements
    quarterly_income = ticker.quarterly_income_stmt
    quarterly_balance = ticker.quarterly_balance_sheet

    # Annual financial statements
    annual_income = ticker.income_stmt
    annual_balance = ticker.balance_sheet

    return {
        "name": info.get("longName"),
        "currency": self._detect_currency(symbol),
        "quarterly_income_statement": self._convert_yahoo_dataframe(quarterly_income),
        "quarterly_balance_sheet": self._convert_yahoo_dataframe(quarterly_balance),
        "annual_income_statement": self._convert_yahoo_dataframe(annual_income),
        "annual_balance_sheet": self._convert_yahoo_dataframe(annual_balance)
    }
```

#### Enhanced Field Mapping (29 Metrics)

**Financial Statement Normalization:**
```python
yahoo_to_agent_mapping = {
    # Income Statement Fields
    "total_revenue": "TotalRevenue",
    "cost_of_revenue": "CostOfRevenue",
    "gross_profit": "GrossProfit",
    "operating_income": "OperatingIncome",
    "net_income": "NetIncome",
    "ebitda": "EBITDA",
    "basic_eps": "BasicEPS",
    "diluted_eps": "DilutedEPS",

    # Balance Sheet Fields
    "total_assets": "TotalAssets",
    "total_current_assets": "TotalCurrentAssets",
    "total_liabilities": "TotalLiabilitiesNetMinorityInterest",
    "total_current_liabilities": "TotalCurrentLiabilities",
    "total_equity": "TotalStockholdersEquity",
    "retained_earnings": "RetainedEarnings",
    "total_debt": "TotalDebt",

    # Cash Flow Fields
    "operating_cash_flow": "OperatingCashFlow",
    "investing_cash_flow": "InvestingCashFlow",
    "financing_cash_flow": "FinancingCashFlow",
    "free_cash_flow": "FreeCashFlow",

    # Additional Metrics
    "market_cap": "market_cap",
    "enterprise_value": "enterprise_value",
    "shares_outstanding": "shares_outstanding",
    "book_value_per_share": "book_value_per_share"
}
```

#### Pandas NaN Detection
```python
def _normalize_yahoo_statement_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
    """Enhanced data normalization with pandas NaN detection"""
    normalized = {}

    for field, value in data.items():
        if pd.isna(value):
            # Handle NaN values appropriately
            normalized[field] = None
        elif isinstance(value, (int, float)):
            # Convert to Decimal for precision
            normalized[field] = Decimal(str(value))
        else:
            normalized[field] = value

    return normalized
```

## Enhanced Agent 2: Forensic Analysis Agent

### Core Functionality

#### 29 Comprehensive Metrics Analysis
```python
class ForensicAnalysisAgent:
    def __init__(self):
        self.analysis_types = [
            "vertical_analysis",    # 11 metrics
            "horizontal_analysis",  # 10 metrics
            "financial_ratios"      # 8 metrics
        ]

    async def analyze_yahoo_finance_data(self, symbol: str, quarters: int = 3) -> Dict[str, Any]:
        """Enhanced real-time forensic analysis"""
        # Get normalized data from Agent 1
        ingestion_agent = DataIngestionAgent()
        yahoo_data = await ingestion_agent.get_financials(symbol, "yahoo", quarters)

        if "error" in yahoo_data:
            return {"success": False, "error": yahoo_data["error"]}

        # Perform comprehensive analysis
        vertical_results = await self._vertical_analysis(yahoo_data)
        horizontal_results = await self._horizontal_analysis(yahoo_data)
        ratio_results = await self._financial_ratios(yahoo_data)

        return {
            "success": True,
            "company_symbol": symbol,
            "data_source": "yahoo_finance",
            "quarters_analyzed": quarters,
            "analysis_date": datetime.now().isoformat(),
            "vertical_analysis": vertical_results,
            "horizontal_analysis": horizontal_results,
            "financial_ratios": ratio_results
        }
```

#### Vertical Analysis (11 Metrics)
```python
async def _vertical_analysis(self, financial_data: Dict[str, Any]) -> Dict[str, Any]:
    """Common-size financial statement analysis"""
    results = {"success": True, "vertical_analysis": {}}

    # Income Statement Analysis (as % of revenue)
    quarterly_income = financial_data.get("quarterly_income_statement", [])
    if quarterly_income:
        latest_income = quarterly_income[0]
        total_revenue = latest_income.get("total_revenue")

        if total_revenue:
            income_percentages = {}
            for field in ["cost_of_revenue", "gross_profit", "operating_income", "net_income"]:
                if field in latest_income and latest_income[field]:
                    value = latest_income[field]
                    if not pd.isna(value):
                        income_percentages[f"{field}_pct"] = (value / total_revenue) * 100

            results["vertical_analysis"]["income_statement"] = income_percentages

    # Balance Sheet Analysis (as % of total assets)
    quarterly_balance = financial_data.get("quarterly_balance_sheet", [])
    if quarterly_balance:
        latest_balance = quarterly_balance[0]
        total_assets = latest_balance.get("total_assets")

        if total_assets:
            balance_percentages = {}
            for field in ["total_current_assets", "total_equity", "total_current_liabilities"]:
                if field in latest_balance and latest_balance[field]:
                    value = latest_balance[field]
                    if not pd.isna(value):
                        balance_percentages[f"{field}_pct"] = (value / total_assets) * 100

            results["vertical_analysis"]["balance_sheet"] = balance_percentages

    return results
```

#### Horizontal Analysis (10 Metrics)
```python
async def _horizontal_analysis(self, financial_data: Dict[str, Any]) -> Dict[str, Any]:
    """Growth rate and trend analysis"""
    results = {"success": True, "horizontal_analysis": {}}

    # Income Statement Growth Analysis
    quarterly_income = financial_data.get("quarterly_income_statement", [])
    if len(quarterly_income) >= 2:
        current = quarterly_income[0]
        previous = quarterly_income[1]

        growth_metrics = {}
        for field in ["total_revenue", "gross_profit", "operating_income", "net_income"]:
            current_val = current.get(field)
            previous_val = previous.get(field)

            if (current_val and previous_val and
                not pd.isna(current_val) and not pd.isna(previous_val)):
                growth_rate = ((current_val - previous_val) / previous_val) * 100
                growth_metrics[f"{field}_growth_pct"] = growth_rate

        results["horizontal_analysis"]["income_statement"] = growth_metrics

    # Balance Sheet Growth Analysis
    quarterly_balance = financial_data.get("quarterly_balance_sheet", [])
    if len(quarterly_balance) >= 2:
        current = quarterly_balance[0]
        previous = quarterly_balance[1]

        growth_metrics = {}
        for field in ["total_assets", "total_equity", "total_debt"]:
            current_val = current.get(field)
            previous_val = previous.get(field)

            if (current_val and previous_val and
                not pd.isna(current_val) and not pd.isna(previous_val)):
                growth_rate = ((current_val - previous_val) / previous_val) * 100
                growth_metrics[f"{field}_growth_pct"] = growth_rate

        results["horizontal_analysis"]["balance_sheet"] = growth_metrics

    return results
```

#### Financial Ratios (8 Metrics)
```python
async def _financial_ratios(self, financial_data: Dict[str, Any]) -> Dict[str, Any]:
    """Comprehensive financial ratio analysis"""
    results = {"success": True, "financial_ratios": {}}

    quarterly_balance = financial_data.get("quarterly_balance_sheet", [])
    quarterly_income = financial_data.get("quarterly_income_statement", [])

    if quarterly_balance and quarterly_income:
        latest_balance = quarterly_balance[0]
        latest_income = quarterly_income[0]

        # Liquidity Ratios
        current_assets = latest_balance.get("total_current_assets")
        current_liabilities = latest_balance.get("total_current_liabilities")
        cash_equivalents = latest_balance.get("cash_and_equivalents", 0)

        if (current_assets and current_liabilities and
            not pd.isna(current_assets) and not pd.isna(current_liabilities)):

            current_ratio = current_assets / current_liabilities
            quick_ratio = (current_assets - latest_balance.get("inventory", 0)) / current_liabilities

            results["financial_ratios"]["current_ratio"] = current_ratio
            results["financial_ratios"]["quick_ratio"] = quick_ratio

            if not pd.isna(cash_equivalents):
                cash_ratio = cash_equivalents / current_liabilities
                results["financial_ratios"]["cash_ratio"] = cash_ratio

        # Profitability Ratios
        total_revenue = latest_income.get("total_revenue")
        net_income = latest_income.get("net_income")
        total_assets = latest_balance.get("total_assets")
        total_equity = latest_balance.get("total_equity")

        if total_revenue and net_income:
            if not pd.isna(total_revenue) and not pd.isna(net_income):
                net_profit_margin = (net_income / total_revenue) * 100
                results["financial_ratios"]["net_profit_margin_pct"] = net_profit_margin

        if total_assets and net_income:
            if not pd.isna(total_assets) and not pd.isna(net_income):
                roa = (net_income / total_assets) * 100
                results["financial_ratios"]["return_on_assets_pct"] = roa

        if total_equity and net_income:
            if not pd.isna(total_equity) and not pd.isna(net_income):
                roe = (net_income / total_equity) * 100
                results["financial_ratios"]["return_on_equity_pct"] = roe

    return results
```

## Enhanced Data Flow Architecture

### Real-time Processing Pipeline

1. **Data Ingestion (Agent 1)**
   - Yahoo Finance API calls
   - Multi-source data aggregation
   - Field mapping normalization (29 fields)
   - Pandas NaN detection and cleaning

2. **Forensic Analysis (Agent 2)**
   - Vertical analysis (11 metrics)
   - Horizontal analysis (10 metrics)
   - Financial ratios (8 metrics)
   - Real-time result generation

3. **Integration Layer**
   - Cross-agent data validation
   - Performance monitoring
   - Error handling and recovery

### Simultaneous Operation

Both agents operate concurrently:
- **Agent 1**: Continuously ingests data from multiple sources
- **Agent 2**: Processes data in real-time as it becomes available
- **Integration**: Seamless data flow between agents
- **Monitoring**: Real-time performance and error tracking

## Enhanced Database Schema

### Enhanced Tables for Real-time Processing

```sql
-- Enhanced financial statements table
CREATE TABLE financial_statements (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(50) NOT NULL,
    statement_type VARCHAR(50) NOT NULL,
    reporting_period VARCHAR(20) NOT NULL,
    fiscal_year INTEGER,
    fiscal_quarter INTEGER,
    data_source VARCHAR(50) NOT NULL,
    statement_data JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Enhanced analysis results table
CREATE TABLE forensic_analysis (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(50) NOT NULL,
    analysis_type VARCHAR(50) NOT NULL,
    data_source VARCHAR(50) NOT NULL,
    analysis_period VARCHAR(20) NOT NULL,
    quarters_analyzed INTEGER NOT NULL,
    analysis_results JSONB NOT NULL,
    analysis_date TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Enhanced data quality tracking
CREATE TABLE data_quality_metrics (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(50) NOT NULL,
    data_source VARCHAR(50) NOT NULL,
    quality_score DECIMAL(5,2),
    null_value_count INTEGER,
    validation_errors JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## Enhanced API Design

### RESTful Endpoints

```python
# Enhanced forensic analysis endpoint
@app.post("/api/v1/forensic/enhanced-analysis")
async def enhanced_forensic_analysis(request: EnhancedAnalysisRequest):
    """Real-time forensic analysis with enhanced features"""

    # Initialize both agents
    ingestion_agent = DataIngestionAgent()
    forensic_agent = ForensicAnalysisAgent()

    # Run both agents simultaneously
    search_results = await ingestion_agent.search_company(request.company_id)
    financial_data = await ingestion_agent.get_financials(
        request.company_id, request.data_source, request.periods
    )
    analysis_results = await forensic_agent.analyze_yahoo_finance_data(
        request.company_id, request.periods
    )

    return {
        "company_search": search_results,
        "financial_data": financial_data,
        "forensic_analysis": analysis_results,
        "processing_time": time.time() - start_time
    }
```

## Enhanced Deployment Architecture

### Production Deployment

```yaml
# Enhanced docker-compose.yml
version: '3.8'
services:
  iris-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - YAHOO_FINANCE_ENABLED=true
      - ENHANCED_FIELD_MAPPING=true
      - PANDAS_NAN_DETECTION=true
      - REAL_TIME_PROCESSING=true

  celery-worker-enhanced:
    build: .
    command: celery -A src.celery_app worker --loglevel=info -Q enhanced_forensic
    environment:
      - ENHANCED_AGENTS=true
      - MULTI_SOURCE_SUPPORT=true

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./config/enhanced-prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
```

## Enhanced Monitoring and Metrics

### Prometheus Metrics

```python
# Enhanced metrics collection
from prometheus_client import Counter, Histogram, Gauge

ENHANCED_ANALYSIS_TOTAL = Counter(
    'enhanced_forensic_analysis_total',
    'Total enhanced forensic analysis jobs',
    ['company_id', 'data_source']
)

YAHOO_FINANCE_REQUESTS = Counter(
    'yahoo_finance_api_requests_total',
    'Total Yahoo Finance API requests',
    ['endpoint', 'status']
)

FIELD_MAPPING_ACCURACY = Gauge(
    'field_mapping_accuracy_ratio',
    'Field mapping accuracy across sources',
    ['source', 'field_count']
)

PANDAS_NAN_DETECTION_RATE = Gauge(
    'pandas_nan_detection_rate',
    'Rate of NaN values detected by pandas',
    ['data_source']
)
```

## Enhanced Error Handling

### Comprehensive Error Management

```python
class EnhancedErrorHandler:
    async def handle_yahoo_finance_error(self, error: Exception, symbol: str) -> Dict[str, Any]:
        """Enhanced error handling for Yahoo Finance failures"""
        logger.error(f"Yahoo Finance error for {symbol}: {error}")

        return {
            "success": False,
            "error": f"Yahoo Finance API error: {str(error)}",
            "error_type": "yahoo_finance_api",
            "timestamp": datetime.now().isoformat(),
            "fallback_attempted": True
        }

    async def handle_field_mapping_error(self, error: Exception, data: Dict) -> Dict[str, Any]:
        """Enhanced error handling for field mapping failures"""
        logger.error(f"Field mapping error: {error}")

        return {
            "success": False,
            "error": f"Field mapping error: {str(error)}",
            "error_type": "field_mapping",
            "fallback_data": self._get_fallback_mapping(data)
        }
```

## Enhanced Testing Strategy

### Comprehensive Test Coverage

```python
class TestEnhancedAgents(unittest.TestCase):
    def setUp(self):
        self.ingestion_agent = DataIngestionAgent()
        self.forensic_agent = ForensicAnalysisAgent()

    async def test_reliance_real_time_analysis(self):
        """Test complete pipeline with real Reliance data"""
        # Test Agent 1
        search_results = await self.ingestion_agent.search_company("RELIANCE.NS")
        self.assertGreater(len(search_results), 0)

        reliance_data = await self.ingestion_agent.get_financials("RELIANCE.NS", "yahoo", 3)
        self.assertNotIn("error", reliance_data)

        # Test Agent 2
        analysis = await self.forensic_agent.analyze_yahoo_finance_data("RELIANCE.NS", 3)
        self.assertTrue(analysis["success"])

        # Test integration
        self.assertEqual(analysis["company_symbol"], "RELIANCE.NS")
        self.assertEqual(analysis["data_source"], "yahoo_finance")
        self.assertIn("vertical_analysis", analysis)
        self.assertIn("horizontal_analysis", analysis)
        self.assertIn("financial_ratios", analysis)

    async def test_enhanced_field_mapping(self):
        """Test 29-field comprehensive mapping"""
        test_data = self._get_test_financial_data()
        normalized = await self.ingestion_agent.normalize_financial_statements(test_data, "yahoo")

        # Verify all 29 fields are present
        expected_fields = [
            "total_revenue", "cost_of_revenue", "gross_profit",
            "operating_income", "net_income", "ebitda",
            # ... all 29 fields
        ]

        for field in expected_fields:
            self.assertIn(field, normalized[0])

    async def test_pandas_nan_detection(self):
        """Test pandas NaN detection and handling"""
        test_data_with_nans = self._get_data_with_nan_values()
        normalized = await self.ingestion_agent.normalize_financial_statements(
            test_data_with_nans, "yahoo"
        )

        # Verify NaN values are properly handled
        for statement in normalized:
            for field, value in statement.items():
                if field in ["total_revenue", "net_income", "total_assets"]:
                    self.assertIsNotNone(value, f"Field {field} should not be None")
```

## Enhanced Performance Optimizations

### Multi-threading and Async Processing

```python
class EnhancedPerformanceOptimizer:
    def __init__(self):
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self.semaphore = asyncio.Semaphore(10)  # Limit concurrent requests

    async def process_multiple_companies(self, symbols: List[str]) -> List[Dict[str, Any]]:
        """Process multiple companies simultaneously"""
        tasks = []

        for symbol in symbols:
            task = asyncio.create_task(
                self._process_single_company(symbol)
            )
            tasks.append(task)

        # Wait for all tasks to complete
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Handle any exceptions
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"Error processing {symbols[i]}: {result}")
                processed_results.append({"error": str(result)})
            else:
                processed_results.append(result)

        return processed_results

    async def _process_single_company(self, symbol: str) -> Dict[str, Any]:
        """Process a single company with enhanced agents"""
        async with self.semaphore:  # Rate limiting
            try:
                # Agent 1 processing
                ingestion_agent = DataIngestionAgent()
                search_results = await ingestion_agent.search_company(symbol)
                financial_data = await ingestion_agent.get_financials(symbol, "yahoo", 3)

                if "error" in financial_data:
                    return {"symbol": symbol, "error": financial_data["error"]}

                # Agent 2 processing
                forensic_agent = ForensicAnalysisAgent()
                analysis = await forensic_agent.analyze_yahoo_finance_data(symbol, 3)

                return {
                    "symbol": symbol,
                    "search_results": search_results,
                    "financial_data": financial_data,
                    "analysis": analysis,
                    "processing_time": time.time() - start_time
                }

            except Exception as e:
                logger.error(f"Error processing {symbol}: {e}")
                return {"symbol": symbol, "error": str(e)}
```

## Enhanced Security Architecture

### Secure Data Handling

```python
class EnhancedSecurityManager:
    def __init__(self):
        self.encryption_key = os.getenv("ENCRYPTION_KEY")
        self.api_key_manager = APIKeyManager()

    async def secure_yahoo_finance_request(self, symbol: str) -> Dict[str, Any]:
        """Make secure Yahoo Finance API requests"""
        headers = {
            "User-Agent": self._get_secure_user_agent(),
            "Accept": "application/json",
            "Accept-Encoding": "gzip, deflate",
            "Accept-Language": "en-US,en;q=0.9",
        }

        # Rate limiting
        await self._enforce_rate_limit("yahoo_finance")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}",
                    headers=headers,
                    timeout=30
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        return await self._decrypt_sensitive_data(data)
                    else:
                        raise Exception(f"Yahoo Finance API error: {response.status}")

        except Exception as e:
            logger.error(f"Secure Yahoo Finance request failed: {e}")
            raise
```

## Conclusion

The enhanced IRIS system design incorporates:

1. **ğŸš€ Enhanced Agent 1 & 2** - Yahoo Finance integration with 29 comprehensive metrics
2. **ğŸ”„ Simultaneous Operation** - Real-time data processing pipeline
3. **ğŸ“Š 29 Comprehensive Metrics** - Complete forensic analysis suite
4. **ğŸ›¡ï¸ Enhanced Security** - Secure API handling and data protection
5. **âš¡ Performance Optimization** - Multi-threaded and async processing
6. **ğŸ“ˆ Scalability** - Multi-company and multi-source support
7. **ğŸ” Enhanced Monitoring** - Comprehensive metrics and alerting

This design enables real-time financial forensics analysis with production-ready capabilities for Indian public companies using live data from Yahoo Finance and other sources.

---

**Design Status**: âœ… **ENHANCED - VERSION 2.0**

**Last Updated**: 2025-10-08

**Enhanced Features**: Real-time processing, 29 metrics, Yahoo Finance integration, simultaneous agent operation
